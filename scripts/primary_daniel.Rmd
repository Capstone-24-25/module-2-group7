---
title: "PrimaryTask"
output: html_document
date: "2024-11-19"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidymodels)
library(tidytext)
library(modelr)
library(Matrix)
library(sparsesvd)
library(glmnet)
library(dplyr)
library(yardstick)
library(tidyr)
library(textstem)
load('../data/cleaned_claims_headers.Rdata')
load('../data/claims-test.Rdata')
# path to activity files on repo
url <- 'https://raw.githubusercontent.com/pstat197/pstat197a/main/materials/activities/data/'
# load functions needed for this assignment
source(paste(url, 'projection-functions.R', sep = ''))
#source('Candis.R')
```

# Pre-processing
```{r}
headers_clean <- cleaned_claims_headers %>%
  select(-c(1:5), -7)
tfidf_header <- headers_clean %>% 
  unnest_tokens(output = token, 
                input = text_clean, 
                token = 'words',
                stopwords = str_remove_all(stop_words$word, 
                                           '[[:punct:]]')) %>%
  mutate(token.lem = lemmatize_words(token)) %>%
  filter(str_length(token.lem) > 2) %>%
  count(.id, bclass, mclass, token.lem, name = 'n') %>%
  bind_tf_idf(term = token.lem, 
              document = .id,
              n = n) %>%
  pivot_wider(id_cols = c('.id', 'bclass', 'mclass'),
              names_from = 'token.lem',
              values_from = 'tf_idf',
              values_fill = 0)
```


# Partition
```{r}
set.seed(111824)
partitions <- tfidf_header %>% 
  initial_split(prop=0.7)

# Separate DTM from labels
test_dtm <- testing(partitions) %>% 
  select(-.id, -bclass, -mclass)
test_labels <- testing(partitions) %>% 
  select(.id, bclass, mclass)

# Now for training test
train_dtm <- training(partitions) %>% 
  select(-.id, -bclass, -mclass)
train_labels <- training(partitions) %>% 
  select(.id, bclass, mclass)
```

# Projection
```{r}
proj_out <- projection_fn(.dtm = train_dtm, .prop = 0.7)
train_dtm_projected <- proj_out$data

# Components used
proj_out$n_pc
```

# Regression
```{r}
train <- train_labels %>%
  transmute(bclass = factor(bclass)) %>%
  bind_cols(train_dtm_projected)

fit <- glm(bclass ~ ., data = train, family='binomial')
```

# Fit regularized logistic regression
```{r}
# store predictors and response as matrix and vector
x_train <- train %>% select(-bclass) %>% as.matrix()
y_train <- train_labels %>% pull(bclass)

# fit enet model
alpha_enet <- 0.3
fit_reg <- glmnet(x = x_train, 
                  y = y_train, 
                  family = 'binomial',
                  alpha = alpha_enet)

# choose a constrait strength by cross-validation
set.seed(112024)
cvout <- cv.glmnet(x = x_train, 
                   y = y_train, 
                   family = 'binomial',
                   alpha = alpha_enet)

# store optimal strength
lambda_opt <- cvout$lambda.min

# view results
cvout
```

# Prediction and testing
```{r}
# project test data onto PCs
test_dtm_projected <- reproject_fn(.dtm = test_dtm, proj_out)

# coerce to matrix
x_test <- as.matrix(test_dtm_projected)

# compute predicted probabilities
preds <- predict(fit_reg, 
                 s = lambda_opt, 
                 newx = x_test,
                 type = 'response')

# store predictions in a data frame with true labels
pred_df <- test_labels %>%
  transmute(bclass = factor(bclass)) %>%
  bind_cols(pred = as.numeric(preds)) %>%
  mutate(bclass.pred = factor(pred > 0.5, 
                              labels = levels(bclass)))

# define classification metric panel 
panel <- metric_set(sensitivity, 
                    specificity, 
                    accuracy, 
                    roc_auc)

# compute test set accuracy
pred_df %>% panel(truth = bclass, 
                  estimate = bclass.pred, 
                  pred, 
                  event_level = 'second')
```


# Multinomial
```{r}
# get multiclass labels
y_train_multi <- train_labels %>% pull(mclass)

# fit enet model
alpha_enet <- 0.2
fit_reg_multi <- glmnet(x = x_train, 
                        y = y_train_multi, 
                        family = 'multinomial',
                        alpha = alpha_enet)

# choose a strength by cross-validation
set.seed(112022)
cvout_multi <- cv.glmnet(x = x_train, 
                         y = y_train_multi, 
                         family = 'multinomial',
                         alpha = alpha_enet)

# view results
cvout

preds_multi <- predict(fit_reg_multi, 
                       s = cvout_multi$lambda.min, 
                       newx = x_test,
                       type = 'response')

as_tibble(preds_multi[, , 1]) 

pred_class <- as_tibble(preds_multi[, , 1]) %>% 
  mutate(row = row_number()) %>%
  pivot_longer(-row, 
               names_to = 'label',
               values_to = 'probability') %>%
  group_by(row) %>%
  slice_max(probability, n = 1) %>%
  pull(label)

pred_tbl <- table(pull(test_labels, mclass), pred_class)

pred_tbl
```

# Evaluate accuracy of multinomial regression
```{r}
results_df <- tibble(
  truth = factor(pull(test_labels, mclass)),
  estimate = factor(pred_class, levels = levels(factor(pull(test_labels, mclass))))
)

panel <- metric_set(sensitivity, 
                    specificity,
                    accuracy)

results <- results_df %>%
  panel(truth = truth, estimate = estimate)

results
```
# Save terms
```{r}
terms <- colnames(tfidf_header)
terms <- terms[!terms %in% c('.id', 'bclass', 'mclass')]
```

# Save models and objects
```{r}
saveRDS(fit_reg, file = "../results/models/binary_model.rds")
saveRDS(fit_reg_multi, file = "../results/models/multiclass_model.rds")
saveRDS(proj_out, file = "../results/models/variables/proj_out.rds")
saveRDS(terms, file = "../results/models/variables/terms.rds")
saveRDS(lambda_opt, file = "../results/models/variables/lambda_opt.rds")
saveRDS(cvout_multi$lambda.min, file = "../results/models/variables/lambda_multi_opt.rds")
```
