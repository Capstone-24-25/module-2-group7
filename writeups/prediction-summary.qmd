---
title: "Predictive modeling of claims status"
author: 'Daniel Ledvin, Keon Dibley, Ziqian Zhao, Candis Wu'
date: today
---

### Abstract

Provide a 3-5 sentence summary of your work on the primary task. Indicate what input data was used, what method was used for binary class predictions, what method was used for multiclass predictions, and what estimated accuracies were achieved.

> *Header and paragraph content was scraped from the raw webpages and processed into term frequencies of word tokens. For binary classification, a two-layer neural network yielded an estimated 81.4% accuracy; for multiclass classification, a support vector machine gave 78% accuracy.*

### Preprocessing

In one paragraph lay out your preprocessing pipeline. No need to provide exact step-by-step detail; just give an overview of the main components:
-   what text content was extracted from HTML
-   how text was cleaned
-   how cleaned text was represented quantitatively

The preprocessing pipeline involved extracting paragraph and header text content from HTML documents. The text was cleaned by removing URLs, emails, punctuation, numbers, symbols, and excessive whitespace, converting text to lowercase, and normalizing words to their base forms via lemmatization. The cleaned text was then tokenized into individual words, with stop words excluded, and represented quantitatively using Term Frequency-Inverse Document Frequency (TF-IDF). This representation was transformed into a document-term matrix (DTM), reduced in dimensionality using Principal Component Analysis (PCA), and used to train a logistic regression model. The binary classification model's performance was evaluated using metrics such as accuracy and AUC, comparing results with and without header content.

### Methods

Describe your final predictive models. Include one paragraph with details on the binary classification approach, and one on the multiclass approach. Include for each:

-   what ML/statistical method was used

-   model specification and hyperparameter selection

-   training method

We explored different techniques to find the most predictive model for binary and multiclass classification. One of our explorations is **Recurrent Neural Networks (RNN)**, specifically a **SimpleRNN** layer, for sequence-based tasks like text classification. The model is set up for **classification** (both binary and multiclass) with a **sigmoid** activation function for binary classification and **softmax** for multiclass classification. 

The model is composed of 4 layers: an **embedding layer** to convert tokenized text into dense vectors, a **SimpleRNN** layer to process and learn patterns in sequences; a **dense layer** and an **activation layer**. The key hyperparameters include an embedding dimension of 128, 64 units in the RNN layer to control model capacity and complexity, and a batch size of 32 to control the model update frequency. The model uses **Adam optimizer**, with **binary crossentropy** loss for binary classification and **categorical crossentropy** loss for multiclass classification.

The model is trained using the **fit()** method for 10 epochs processes 32 sequences at a time.The performance is measured using **accuracy** as the primary metric. After training, the model is evaluated on test data. The binary classification has an **accuracy** about **0.757**, with a **sensitivity** around **0.686** and **specificity** around **0.813**. The multi-class classification has an accuracy about **0.696**, with an overall sensitivity **0.635** and overall specificity **0.913**. The predicted result is stored as `results/preds-group7-RNN.RData`




### Results

Indicate the predictive accuracy of the binary classifications and the multiclass classifications. Provide a table for each, and report sensitivity, specificity, and accuracy.[^1]

[^1]: Read [this article](https://yardstick.tidymodels.org/articles/multiclass.html) on multiclass averaging.
