---
title: "Predictive modeling of claims status"
author: 'Daniel Ledvin, Keon Dibley, Ziqian Zhao, Candis Wu'
date: today
---

### Abstract

In this report, two predictive models were developed to classify claims data, one using a binary approach and the other using a multiclass approach. Header and paragraph data was scraped from raw webpages, then cleaned and processed into term frequencies of word tokens. For binary classification, a regularized logistic regression with Elastic Net regularization was used, achieving an estimated accuracy of 81.1%. For multiclass classification, a multinomial logistic regression model with Elastic Net regularization was used, which gave an estimated 76.3% accuracy.

### Preprocessing

The preprocessing pipeline involved extracting paragraph and header text content from HTML documents. The text was cleaned by removing URLs, emails, punctuation, numbers, symbols, and excessive whitespace, converting text to lowercase, and normalizing words to their base forms via lemmatization. The cleaned text was then tokenized into individual words, with stop words excluded, and represented quantitatively using Term Frequency-Inverse Document Frequency (TF-IDF). This representation was transformed into a document-term matrix (DTM), reduced in dimensionality using Principal Component Analysis (PCA), and used to train a logistic regression model. The binary classification model's performance was evaluated using metrics such as accuracy and AUC, comparing results with and without header content.

### Methods

We explored different techniques to find the most predictive model for binary and multiclass classification. Our best model turned out to be a **Regularized Logistic Regression** model with **Elastic Net** regularization. This method works well with high-dimensional text data and balances between L1 and L2 regularization to improve model performance.

For the **binary classification**, our goal was to predict whether a claim contained relevant information. This model specification included a mixing parameter 'alpha = 0.3', which balanced lasso and ridge penalties. The regularization parameter 'lambda' was optimized using **cross-validation** to minimize cross-validated error, helping to prevent overfitting. This model used the **binomial family** for its classification.

For the **multiclass classification**, we aimed to predict if claims fell into specific categories or if they had no relevant information at all. We used the **multinomial family** parameter to allow for the model to handle multiple classes. The multiclass model used a mixing parameter 'alpha = 0.2', which places a greater emphasis on ridge regularization. This is more helpful in the case of multiclass classification since words that would be shrunk to zero by the lasso penalty might prove to be useful in determining which class a claim may fall into. As with the binary approach, the 'lambda' parameter was determined through **cross-validation**, optimizing the model's predictive accuracy across all classes.

Both models were trained on a dataset split, where 70% of data was partitioned into training data and the remaining 30% was used for testing. Then, the training data was preprocessed, transformed into a **Term Frequency-Inverse Document Frequency (TF-IDF)** matrix, projected into **Principal Components**, and final used to train the models. The test data was then fed back into the models to find how well our models performed.

### Results

|   Metric    | Binary Estimate | Multiclass Estimate |
|:-----------:|:---------------:|:-------------------:|
| Sensitivity |    0.8209877    |      0.5768534      |
| Specificity |    0.8006536    |      0.9156054      |
|  Accuracy   |    0.8111111    |      0.7634921      |
